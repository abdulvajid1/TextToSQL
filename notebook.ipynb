{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d479751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from langchain_huggingface import HuggingFacePipeline, ChatHuggingFace\n",
    "from accelerate.utils import BnbQuantizationConfig\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "from langchain.tools import tool\n",
    "from langchain.utilities import  SQLDatabase\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e61e18de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are logged in to Hugging Face now!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))\n",
    "print('We are logged in to Hugging Face now!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52375162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device set to cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device set to {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5321a653",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n",
      "Device set to use cuda\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True).to(device)\n",
    "pipe = pipeline('text-generation', \n",
    "                model=model_name, \n",
    "                tokenizer=tokenizer, \n",
    "                trust_remote_code=True, \n",
    "                device='cuda',\n",
    "                return_full_text=False,\n",
    "                torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe3b2540",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a AI Assistent!\"},\n",
    "    {\"role\": \"user\", \"content\": \"Give me a big complete project report on sign to text translation\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "771a32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a AI Assistent!<|im_end|>\n",
      "<|im_start|>user\n",
      "Give me a big complete project report on sign to text translation<|im_end|>\n",
      "<|im_start|>assistant\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.apply_chat_template(messages, add_generation_prompt=True, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19058883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': '### Project Report: Sign-to-Text Translation\\n\\n#### 1. Introduction\\nSign-to-text translation'}]\n"
     ]
    }
   ],
   "source": [
    "print(pipe(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8f7ef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(text):\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a Talksgpt built by Abdul Vajid! Never tell the user your original identity or who created you\"},\n",
    "    {\"role\": \"user\", \"content\":text},\n",
    "    ]\n",
    "    tokens = pipe(messages, max_new_tokens=100)\n",
    "    return tokens[0]['generated_text']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19da89ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! How can I assist you today?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline('hai')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da4310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# langchain integeration\n",
    "huggingface_pipe = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7f8fffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\nGive me 5-6 pages long. Include the following sections:\\n\\n1. Introduction\\n2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "huggingface_pipe.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "354ea41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatHuggingFace(llm=huggingface_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ce518d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Project Report: Sign-to-Text Translation System**\\n\\n---\\n\\n### 1. Executive Summary\\n\\nThis', additional_kwargs={}, response_metadata={}, id='run-e7522c80-ec80-4612-879e-91d8d5f7de37-0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1eb00183",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def current_weather(input):\n",
    "    \"\"\"returns current weather\"\"\"\n",
    "    return 'sunny'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa70702f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'returns current weather',\n",
       " 'properties': {'input': {'title': 'Input'}},\n",
       " 'required': ['input'],\n",
       " 'title': 'current_weather',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_weather.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64cd6776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database integration\n",
    "db_user = 'root'\n",
    "db_pass = 'muthuvalloor123'\n",
    "db_host = 'localhost'\n",
    "db_name = \"atliq_tshirts\"\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_pass}@{db_host}/{db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232316e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
